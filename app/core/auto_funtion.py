import os
import json
import re
import math
import logging
import subprocess
import sys
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# ============================================================================
# PATCH: CH·∫∂N C·ª¨A S·ªî CMD KHI CH·∫†Y FFMPEG V√Ä EDGE-TTS (WINDOWS)
# ============================================================================
if os.name == 'nt':
    import asyncio
    
    # 1. Thi·∫øt l·∫≠p c·∫•u h√¨nh kh·ªüi t·∫°o ti·∫øn tr√¨nh ·∫©n
    _startupinfo = subprocess.STARTUPINFO()
    _startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
    _startupinfo.wShowWindow = subprocess.SW_HIDE
    
    _creationflags = 0x08000000  # CREATE_NO_WINDOW

    # 2. Patch subprocess.Popen g·ªëc
    _original_popen = subprocess.Popen
    def _patched_popen(*args, **kwargs):
        if 'startupinfo' not in kwargs:
            kwargs['startupinfo'] = _startupinfo
        if 'creationflags' not in kwargs:
            kwargs['creationflags'] = _creationflags
        return _original_popen(*args, **kwargs)
    subprocess.Popen = _patched_popen

    # 3. √âp asyncio d√πng ProactorEventLoop (tr√°nh nh√°y c·ª≠a s·ªï khi d√πng edge-tts)
    if sys.version_info >= (3, 7):
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
# ============================================================================

# Import h√†m export_to_srt t·ª´ utils (ƒë√£ c√≥ s·∫µn logic ƒë·ªçc draft_content.json)
try:
    from app.core.utils import export_to_srt, milliseconds_to_srt_time
except ImportError:
    from utils import export_to_srt, milliseconds_to_srt_time


# ========== STEP 1: Extract SRT from Draft Content JSON ==========
def extract_srt_from_draft(draft_json_path, output_dir):
    """
    ƒê·ªçc file draft_content.json v√† xu·∫•t ra file auto_subtitle.srt
    trong th∆∞ m·ª•c 'auto' (s·∫Ω ƒë∆∞·ª£c t·∫°o n·∫øu ch∆∞a c√≥).
    
    S·ª≠ d·ª•ng logic t·ª´ utils.export_to_srt() - ƒë√£ ƒë∆∞·ª£c test v√† ho·∫°t ƒë·ªông ƒë√∫ng.
    
    Args:
        draft_json_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file draft_content.json
        output_dir: Th∆∞ m·ª•c g·ªëc l√†m vi·ªác (work_dir)
        
    Returns:
        (success: bool, output_path: str ho·∫∑c error_message: str)
    """
    logging.info(f"[Step 1] B·∫Øt ƒë·∫ßu Extract SRT t·ª´: {os.path.basename(draft_json_path)}")
    
    if not os.path.exists(draft_json_path):
        error_msg = f"File kh√¥ng t·ªìn t·∫°i: {draft_json_path}"
        logging.error(error_msg)
        return False, error_msg
    
    try:
        # T·∫°o th∆∞ m·ª•c 'auto' ƒë·ªÉ l∆∞u output
        auto_dir = os.path.join(output_dir, "auto")
        os.makedirs(auto_dir, exist_ok=True)
        
        # Output path
        output_path = os.path.join(auto_dir, "auto_subtitle.srt")
        
        # S·ª≠ d·ª•ng h√†m export_to_srt t·ª´ utils.py
        success = export_to_srt(draft_json_path, output_path)
        
        if success:
            logging.info(f"[Step 1] Extract th√†nh c√¥ng -> {output_path}")
            return True, output_path
        else:
            return False, "Kh√¥ng th·ªÉ xu·∫•t SRT t·ª´ draft"
        
    except Exception as e:
        error_msg = f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"
        logging.error(error_msg)
        return False, error_msg


# ========== STEP 2: Extract Text from SRT & Split into Parts ==========
def run_step2_split(srt_path, output_dir, split_by_lines=True, value=100):
    """
    B∆∞·ªõc 2: Tr√≠ch xu·∫•t text t·ª´ SRT (Step 1) v√† chia th√†nh nhi·ªÅu file TXT.
    
    Args:
        srt_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file SRT t·ª´ Step 1 (auto/auto_subtitle.srt)
        output_dir: Th∆∞ m·ª•c g·ªëc l√†m vi·ªác (work_dir)
        split_by_lines: True = chia theo s·ªë d√≤ng/file, False = chia theo s·ªë ph·∫ßn
        value: S·ªë d√≤ng m·ªói file (n·∫øu split_by_lines=True) ho·∫∑c s·ªë ph·∫ßn (n·∫øu False)
        
    Returns:
        (success: bool, result: str ho·∫∑c error_message)
    """
    logging.info(f"[Step 2] B·∫Øt ƒë·∫ßu Split t·ª´: {os.path.basename(srt_path)}")
    
    if not os.path.exists(srt_path):
        error_msg = f"File SRT kh√¥ng t·ªìn t·∫°i: {srt_path}"
        logging.error(error_msg)
        return False, error_msg
    
    try:
        # Th∆∞ m·ª•c output: auto/text/
        text_dir = os.path.join(output_dir, "auto", "text")
        os.makedirs(text_dir, exist_ok=True)
        
        # B∆∞·ªõc 2.1: Tr√≠ch xu·∫•t text t·ª´ SRT
        texts = extract_text_lines_from_srt(srt_path)
        
        if not texts:
            return False, "Kh√¥ng t√¨m th·∫•y text trong file SRT"
        
        logging.info(f"[Step 2] Tr√≠ch xu·∫•t ƒë∆∞·ª£c {len(texts)} d√≤ng text t·ª´ SRT")
        
        # B∆∞·ªõc 2.2: Chia th√†nh nhi·ªÅu file
        total_lines = len(texts)
        
        if split_by_lines:
            lines_per_file = int(value)
            num_files = math.ceil(total_lines / lines_per_file)
        else:
            num_parts = int(value)
            lines_per_file = math.ceil(total_lines / num_parts)
            num_files = num_parts

        created_files = []
        for i in range(num_files):
            start_idx = i * lines_per_file
            end_idx = start_idx + lines_per_file
            if start_idx >= total_lines: 
                break
            
            chunk = texts[start_idx:end_idx]

            file_start = start_idx + 1
            file_end = min(end_idx, total_lines)
            filename = f"part_{i+1}_lines_{file_start}-{file_end}.txt"
            file_path = os.path.join(text_dir, filename)

            with open(file_path, "w", encoding="utf-8") as out:
                for line in chunk:
                    out.write(line + "\n")
            
            created_files.append(filename)
            logging.info(f"  - ƒê√£ t·∫°o: {filename}")

        logging.info(f"[Step 2] Chia file ho√†n t·∫•t: T·ªïng {len(created_files)} file trong {text_dir}")
        return True, f"ƒê√£ t·∫°o {len(created_files)} file trong auto/text/"

    except Exception as e:
        error_msg = f"L·ªói Step 2: {e}"
        logging.error(error_msg)
        return False, error_msg


def extract_text_lines_from_srt(srt_path):
    """Tr√≠ch xu·∫•t danh s√°ch d√≤ng text t·ª´ file SRT (b·ªè timing)"""
    texts = []
    try:
        with open(srt_path, "r", encoding="utf-8") as f:
            content = f.read()

        blocks = re.split(r'\n\s*\n', content.strip())

        for block in blocks:
            lines = block.strip().split("\n")
            # T√¨m d√≤ng c√≥ timestamp
            for idx, line in enumerate(lines):
                if "-->" in line:
                    # Text n·∫±m sau d√≤ng timestamp
                    text_lines = lines[idx+1:]
                    if text_lines:
                        # G·ªôp c√°c d√≤ng text (n·∫øu subtitle c√≥ nhi·ªÅu d√≤ng)
                        text = " ".join(text_lines).strip()
                        if text:
                            texts.append(text)
                    break
    except Exception as e:
        logging.error(f"L·ªói ƒë·ªçc SRT: {e}")
    
    return texts


# ========== STEP 3: Call Gemini API for Translation ==========
def run_step3_translate(work_dir, model, max_workers=3, progress_callback=None):
    """
    B∆∞·ªõc 3: D·ªãch t·∫•t c·∫£ c√°c file part b·∫±ng Gemini API.
    
    THU·∫¨T TO√ÅN:
    1. G·ª≠i c√°c request d·ªãch song song v·ªõi kho·∫£ng c√°ch 2 gi√¢y gi·ªØa m·ªói request.
    2. Kh√¥ng c·∫ßn ƒë·ª£i file tr∆∞·ªõc ho√†n th√†nh m·ªõi g·ª≠i file ti·∫øp theo.
    3. N·∫øu file n√†o l·ªói ‚Üí retry l·∫°i sau khi t·∫•t c·∫£ files ƒë√£ th·ª≠ xong.
    4. N·∫øu t·∫•t c·∫£ keys b·ªã rate limit ‚Üí chuy·ªÉn model.
    """
    logging.info(f"[Step 3] B·∫Øt ƒë·∫ßu d·ªãch. Model kh·ªüi ƒëi·ªÉm: {model}")

    # Import dependencies
    try:
        from app.core import gemini
        from app.core.api_manager import get_api_manager
    except ImportError:
        import gemini
        from api_manager import get_api_manager
    
    # 1. Setup paths
    text_dir = os.path.join(work_dir, "auto", "text")
    if not os.path.exists(text_dir):
        return False, "Th∆∞ m·ª•c auto/text kh√¥ng t·ªìn t·∫°i. H√£y ch·∫°y Step 2 tr∆∞·ªõc."
    
    part_files = sorted([f for f in os.listdir(text_dir) if f.startswith("part_") and f.endswith(".txt")])
    if not part_files:
        return False, "Kh√¥ng t√¨m th·∫•y file n√†o ƒë·ªÉ d·ªãch trong auto/text/"
    
    # 2. Setup Resources
    api_manager = get_api_manager()
    api_manager.reload()
    
    prompt_template = gemini.load_prompt_template()
    if not prompt_template:
        return False, "Kh√¥ng th·ªÉ ƒë·ªçc file prompt template."
        
    translated_dir = os.path.join(work_dir, "auto", "translated")
    os.makedirs(translated_dir, exist_ok=True)

    # 3. Model Hierarchy & Fallback Setup
    MODEL_PRIORITY = [
        "gemini-3-pro-preview", 
        "gemini-2.5-pro",
        "gemini-3-flash-preview", 
        "gemini-2.5-flash", 
        "gemini-2.0-flash",
        "gemini-2.5-flash-lite"
    ]
    
    current_model = model
    completed_files = set()
    errors_encountered = []
    
    if current_model not in MODEL_PRIORITY:
        MODEL_PRIORITY = [current_model] + [m for m in MODEL_PRIORITY if m != current_model]

    # C·∫•u h√¨nh
    STAGGER_DELAY = 2.0  # Delay 2 gi√¢y gi·ªØa c√°c request
    MAX_RETRIES = 2  # S·ªë l·∫ßn retry t·ªëi ƒëa cho m·ªói file
    
    # Lock ƒë·ªÉ thread-safe logging v√† results
    results_lock = threading.Lock()
    
    def translate_single_file(filename, model_name, api_key_info=None, retry_count=0):
        """H√†m d·ªãch m·ªôt file ƒë∆°n l·∫ª (ch·∫°y trong thread)"""
        input_path = os.path.join(text_dir, filename)
        output_filename = filename.replace(".txt", "_translated.txt")
        output_path = os.path.join(translated_dir, output_filename)
        
        # N·∫øu c√≥ api_key_info truy·ªÅn v√†o, s·ª≠ d·ª•ng n√≥
        if api_key_info:
            api_keys_to_use = [api_key_info]
        else:
            api_keys_to_use = []  # ƒê·ªÉ gemini.translate_file t·ª± l·∫•y
        
        success, msg = gemini.translate_file(
            file_path=input_path,
            output_path=output_path,
            api_keys=api_keys_to_use,
            model=model_name,
            prompt_template=prompt_template
        )
        
        return {
            "filename": filename,
            "success": success,
            "message": msg,
            "retry_count": retry_count,
            "api_used": api_key_info.get("name", "Unknown") if api_key_info else "Auto"
        }

    # --- MAIN LOOP: Process files with model fallback ---
    files_to_process = list(part_files)
    
    while files_to_process:
        logging.info(f">>> [Step 3 Session] X·ª≠ l√Ω {len(files_to_process)} files v·ªõi model: {current_model}")
        
        # Reset rate_limited status tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu v·ªõi model m·ªõi
        api_manager.reset_all_status_except_disabled()
        
        batch_results = []
        all_keys_exhausted = False
        
        # === G·ª¨I C√ÅC REQUEST SONG SONG V·ªöI STAGGER ===
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            
            for i, filename in enumerate(files_to_process):
                # Stagger delay - ch·ªù 2 gi√¢y gi·ªØa m·ªói l·∫ßn submit (tr·ª´ file ƒë·∫ßu ti√™n)
                if i > 0:
                    time.sleep(STAGGER_DELAY)
                
                # L·∫•y API key tr∆∞·ªõc ƒë·ªÉ hi·ªÉn th·ªã trong log
                api_key, key_info = api_manager.get_next_api_key()
                
                if api_key and key_info:
                    api_name = key_info.get("name", "Unknown")
                    api_key_info = {"api_key": api_key, "name": api_name}
                    logging.info(f"   üì§ [{i+1}/{len(files_to_process)}] {filename} ‚Üí {api_name}")
                else:
                    api_key_info = None
                    logging.warning(f"   üì§ [{i+1}/{len(files_to_process)}] {filename} ‚Üí Kh√¥ng c√≥ key available!")
                
                future = executor.submit(translate_single_file, filename, current_model, api_key_info)
                futures[future] = filename
            
            # Thu th·∫≠p k·∫øt qu·∫£ khi ho√†n th√†nh
            for future in as_completed(futures):
                result = future.result()
                batch_results.append(result)
                
                if result["success"]:
                    logging.info(f"   ‚úì {result['filename']} ({result['api_used']})")
                elif result["message"] == "RATE_LIMIT_ALL_KEYS":
                    logging.warning(f"   ‚ö† Rate limit: {result['filename']}")
                    all_keys_exhausted = True
                else:
                    logging.error(f"   ‚úó {result['filename']}: {result['message']}")
        
        # === X·ª¨ L√ù K·∫æT QU·∫¢ ===
        batch_completed = []
        batch_failed = []
        
        for result in batch_results:
            if result["success"]:
                batch_completed.append(result["filename"])
                completed_files.add(result["filename"])
            else:
                batch_failed.append(result)
        
        # C·∫≠p nh·∫≠t danh s√°ch files c√≤n l·∫°i
        files_to_process = [f for f in part_files if f not in completed_files]
        
        if not files_to_process:
            logging.info(">>> ƒê√£ d·ªãch xong t·∫•t c·∫£ c√°c file.")
            break
        
        # === RETRY C√ÅC FILE B·ªä L·ªñI (kh√¥ng ph·∫£i rate limit) ===
        retry_files = [r for r in batch_failed if r["message"] != "RATE_LIMIT_ALL_KEYS" and r["retry_count"] < MAX_RETRIES]
        
        if retry_files and not all_keys_exhausted:
            logging.info(f">>> Retry {len(retry_files)} file b·ªã l·ªói...")
            time.sleep(2)  # Wait a bit before retry
            
            for result in retry_files:
                filename = result["filename"]
                retry_count = result["retry_count"] + 1
                
                logging.info(f"   üîÑ Retry [{retry_count}/{MAX_RETRIES}] {filename}")
                retry_result = translate_single_file(filename, current_model, retry_count)
                
                if retry_result["success"]:
                    completed_files.add(filename)
                    logging.info(f"   ‚úì Retry th√†nh c√¥ng {filename}")
                else:
                    errors_encountered.append(f"{filename}: {retry_result['message']}")
                    logging.error(f"   ‚úó Retry th·∫•t b·∫°i {filename}: {retry_result['message']}")
                
                time.sleep(1)
            
            # C·∫≠p nh·∫≠t l·∫°i danh s√°ch
            files_to_process = [f for f in part_files if f not in completed_files]
        
        # === CHUY·ªÇN MODEL N·∫æU H·∫æT KEYS ===
        if all_keys_exhausted and files_to_process:
            try:
                curr_idx = MODEL_PRIORITY.index(current_model)
                if curr_idx + 1 < len(MODEL_PRIORITY):
                    next_model = MODEL_PRIORITY[curr_idx + 1]
                    logging.info(f"üîÉ T·ª∞ ƒê·ªòNG CHUY·ªÇN MODEL: {current_model} ‚ûî {next_model}")
                    current_model = next_model
                    api_manager.reset_all_status_except_disabled()
                    continue 
                else:
                    logging.error("ƒê√£ h·∫øt danh s√°ch model d·ª± ph√≤ng! Kh√¥ng th·ªÉ ti·∫øp t·ª•c.")
                    break
            except ValueError:
                logging.error(f"Model {current_model} kh√¥ng n·∫±m trong danh s√°ch fallback.")
                break
        elif not batch_completed and batch_failed:
            # Kh√¥ng c√≥ file n√†o th√†nh c√¥ng v√† c√≥ l·ªói ‚Üí d·ª´ng l·∫°i
            logging.warning(f"Kh√¥ng c√≥ file n√†o d·ªãch th√†nh c√¥ng. D·ª´ng l·∫°i.")
            break

    # === MERGE RESULTS ===
    success_count = len(completed_files)
    
    if success_count > 0:
        try:
            merged_path = os.path.join(work_dir, "auto", "translated_full.txt")
            translated_files = []
            for part in part_files:
                if part in completed_files:
                    t_name = part.replace(".txt", "_translated.txt")
                    if os.path.exists(os.path.join(translated_dir, t_name)):
                        translated_files.append(t_name)
            
            all_lines = []
            for tf in translated_files:
                tf_path = os.path.join(translated_dir, tf)
                with open(tf_path, "r", encoding="utf-8") as f:
                    lines = [line.strip() for line in f if line.strip()]
                    all_lines.extend(lines)
            
            with open(merged_path, "w", encoding="utf-8") as f:
                for line in all_lines:
                    f.write(line + "\n")
            
            srt_template = os.path.join(work_dir, "auto", "auto_subtitle.srt")
            output_srt = os.path.join(work_dir, "auto", "translated_subtitle.srt")
            if os.path.exists(srt_template):
                srt_success, srt_count = convert_txt_to_srt_using_template(merged_path, srt_template, output_srt)
        except Exception as e:
            logging.error(f"Merge error: {e}")

    files_remaining = [f for f in part_files if f not in completed_files]
    if not files_remaining:
        return True, f"Ho√†n th√†nh 100% ({success_count} files)"
    elif success_count > 0:
        return True, f"Ho√†n th√†nh m·ªôt ph·∫ßn {success_count}/{len(part_files)}. L·ªói: {len(files_remaining)} file."
    else:
        return False, f"Th·∫•t b·∫°i ho√†n to√†n. {errors_encountered[:1]}"


def convert_txt_to_srt_using_template(txt_path, srt_template_path, output_srt_path):
    """
    Thay th·∫ø text trong SRT template b·∫±ng text ƒë√£ d·ªãch.
    Gi·ªØ nguy√™n timing, ch·ªâ thay ƒë·ªïi n·ªôi dung.
    """
    logging.info(f"Convert TXT -> SRT: {os.path.basename(txt_path)}")
    try:
        with open(txt_path, "r", encoding="utf-8") as f:
            txt_lines = [l.strip() for l in f if l.strip()]

        with open(srt_template_path, "r", encoding="utf-8") as f:
            srt_content = f.read()

        # Parse SRT blocks
        pattern = r"(\d+)\s*\n(\d{2}:\d{2}:\d{2},\d{3}\s*-->\s*\d{2}:\d{2}:\d{2},\d{3})\s*\n((?:(?!\n\d+\n\d{2}:\d{2}:\d{2},\d{3}).)*)"
        blocks = re.findall(pattern, srt_content, re.DOTALL)
        
        if not blocks:
            # Fallback parsing
            logging.warning("Regex kh√¥ng b·∫Øt ƒë∆∞·ª£c c·∫•u tr√∫c chu·∫©n, th·ª≠ fallback parsing...")
            raw_blocks = re.split(r'\n\s*\n', srt_content.strip())
            parsed_blocks = []
            for b in raw_blocks:
                lines = b.strip().split('\n')
                if len(lines) >= 2:
                    for idx, line in enumerate(lines):
                        if "-->" in line:
                            seq = lines[0] if idx > 0 else str(len(parsed_blocks) + 1)
                            parsed_blocks.append((seq, line))
                            break
            blocks = parsed_blocks

        count = min(len(txt_lines), len(blocks))
        new_content = ""

        for i in range(count):
            seq_num = blocks[i][0] if blocks[i][0] else str(i+1)
            timing = blocks[i][1]
            text = txt_lines[i]
            new_content += f"{seq_num}\n{timing}\n{text}\n\n"

        with open(output_srt_path, "w", encoding="utf-8") as f:
            f.write(new_content)

        logging.info(f"Convert th√†nh c√¥ng: {count} lines -> {output_srt_path}")
        return True, count

    except Exception as e:
        logging.error(f"L·ªói convert_txt_to_srt: {e}")
        return False, 0


# ========== STEP 4: Generate TTS Audio ==========
def run_step4_tts(work_dir, voice, rate, volume, speed_factor=1.0, capcut_speed=0, progress_callback=None):
    """
    B∆∞·ªõc 4: T·∫°o audio t·ª´ SRT ƒë√£ d·ªãch (H·ªó tr·ª£ Edge TTS v√† CapCut TTS)
    
    Args:
        work_dir: Th∆∞ m·ª•c l√†m vi·ªác g·ªëc
        voice: T√™n gi·ªçng ƒë·ªçc (Edge ho·∫∑c CapCut)
        rate: T·ªëc ƒë·ªô ƒë·ªçc (cho Edge TTS, v√≠ d·ª• "+30%")
        volume: √Çm l∆∞·ª£ng (cho Edge TTS, v√≠ d·ª• "+30%")
        speed_factor: H·ªá s·ªë scale th·ªùi gian SRT
        capcut_speed: T·ªëc ƒë·ªô ƒë·ªçc cho CapCut (int, -10 ƒë·∫øn 10, default 0)
        progress_callback: Callback c·∫≠p nh·∫≠t UI
        
    Returns:
        (success: bool, result_message: str)
    """
    import asyncio
    
    # Import
    from app.config.list_voice_capcut import get_voice_id_by_name
    from app.core.tts_capcut_function import tts_batch_sync
    # Import Edge TTS functions
    try:
        from app.core.tts_funtion import (
            parse_srt_file, 
            generate_batch_audio_logic,
            get_safe_filename
        )
    except ImportError:
        from tts_funtion import (
            parse_srt_file,
            generate_batch_audio_logic,
            get_safe_filename
        )

    logging.info(f"[Step 4] B·∫Øt ƒë·∫ßu TTS. Voice: {voice} | Rate: {rate} | CapCut Speed: {capcut_speed}")

    # ƒê∆∞·ªùng d·∫´n input/output
    srt_input = os.path.join(work_dir, "auto", "translated_subtitle.srt")
    audio_dir = os.path.join(work_dir, "auto", "audio")
    
    # T√™n file output c√≥ th√™m t·ªëc ƒë·ªô n·∫øu != 1.0
    if speed_factor != 1.0:
        output_audio = os.path.join(work_dir, "auto", f"merged_audio_{speed_factor}x.wav")
    else:
        output_audio = os.path.join(work_dir, "auto", "merged_audio.wav")
    
    if not os.path.exists(srt_input):
        return False, "File translated_subtitle.srt kh√¥ng t·ªìn t·∫°i. H√£y ch·∫°y Step 3 tr∆∞·ªõc."
    
    # Parse SRT
    entries = parse_srt_file(srt_input)
    if not entries:
        return False, "Kh√¥ng t√¨m th·∫•y subtitle trong file SRT"
    
    logging.info(f"[Step 4] T√¨m th·∫•y {len(entries)} subtitle entries")
    
    # T·∫°o th∆∞ m·ª•c audio
    os.makedirs(audio_dir, exist_ok=True)
    
    # Ki·ªÉm tra xem ƒë√¢y l√† gi·ªçng CapCut hay Edge
    capcut_voice_id = get_voice_id_by_name(voice) if voice else None
    
    audio_files = [] # List[(path, start_ms)]
    
    if capcut_voice_id:
        # === X·ª≠ l√Ω CapCut TTS ===
        logging.info(f"[Step 4] Ph√°t hi·ªán gi·ªçng CapCut: {voice} -> ID: {capcut_voice_id}")
        
        texts = [e.text for e in entries]
        
        # G·ªçi h√†m tts_batch_sync c·ªßa CapCut
        # Pattern file name kh·ªõp v·ªõi h√†m get_safe_filename c·ªßa Edge TTS ƒë·ªÉ t∆∞∆°ng th√≠ch format
        # get_safe_filename tr·∫£ v·ªÅ: "{index:03d}_{safe_text}.wav"
        
        # L∆∞u √Ω: tts_batch_sync d√πng index i+1 (1-based) khi format filename.
        # Ch√∫ng ta c·∫ßn ƒë·∫£m b·∫£o index kh·ªõp v·ªõi entries (entries c√≥ index).
        
        # C√°ch t·ªët nh·∫•t l√† d√πng m·ªôt custom mapping ho·∫∑c ƒë∆°n gi·∫£n l√† t·∫°o file xong r·ªìi map l·∫°i
        # Tuy nhi√™n tts_batch_sync nh·∫≠n list text v√† x·ª≠ l√Ω tu·∫ßn t·ª±.
        
        # Ta s·∫Ω d√πng text[:20] l√†m safe name cho ƒë∆°n gi·∫£n v√† consistent
        # Nh∆∞ng CapCut function c·∫ßn filename_pattern ƒë∆°n gi·∫£n.
        # H√£y d√πng pattern: "{index:03d}_audio.wav" ƒë·ªÉ tr√°nh l·ªói k√Ω t·ª± ƒë·∫∑c bi·ªát
        # Sau ƒë√≥ ch√∫ng ta s·∫Ω rename l·∫°i ho·∫∑c just create mapping based on index.
        
        capcut_results = tts_batch_sync(
            texts=texts,
            output_dir=audio_dir,
            speaker=capcut_voice_id,
            audio_format="wav",
            speech_rate=capcut_speed,
            filename_pattern="{index:03d}_cc.wav", # Temp simple name
            verbose=True
        )
        
        # Map k·∫øt qu·∫£ tr·∫£ v·ªÅ v√†o audio_files list
        # tts_batch_sync tr·∫£ v·ªÅ List[TTSResult]
        # TTSResult c√≥ index (0-based from texts list), output_path, success
        
        for res in capcut_results:
            if res.success and res.index < len(entries):
                entry = entries[res.index] # entries t∆∞∆°ng ·ª©ng
                
                # ƒê·ªÉ t∆∞∆°ng th√≠ch v·ªõi logic merge ph√≠a sau (d·ª±a tr√™n t√™n file ƒë·ªÉ t√¨m),
                # ho·∫∑c logic merge ch·∫•p nh·∫≠n list[(path, start)].
                # H√†m merge_audio_files_ffmpeg nh·∫≠n list[(path, start)].
                # N√™n ta ch·ªâ c·∫ßn add v√†o list l√† ƒë∆∞·ª£c.
                
                audio_files.append((res.output_path, entry.start_ms))
            else:
                logging.error(f"CapCut TTS failed for index {res.index}: {res.error_message}")

    else:
        # === X·ª≠ l√Ω Edge TTS (C≈©) ===
        async def run_tts():
            return await generate_batch_audio_logic(
                entries=entries,
                output_dir=audio_dir,
                voice=voice,
                rate=rate,
                volume=volume,
                pitch="+0Hz",
                max_concurrent=5,
                stop_event=None,
                progress_callback=None
            )
        
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            audio_files = loop.run_until_complete(run_tts())
            loop.close()
            
            # Retry logic ch·ªâ √°p d·ª•ng cho Edge TTS v√¨ CapCut logic ƒë∆°n gi·∫£n h∆°n (v√† c√≥ retry n·ªôi b·ªô n·∫øu c·∫ßn thi·∫øt k·∫ø th√™m)
            # Tuy nhi√™n ƒë·ªÉ code g·ªçn, ta gi·ªØ retry logic ri√™ng cho Edge ho·∫∑c t√≠ch h·ª£p sau.
            # ·ªû ƒë√¢y ta t√°i s·ª≠ d·ª•ng logic validate ch·ªâ cho Edge, ho·∫∑c chung?
            # V·ªõi CapCut, ta ƒë√£ c√≥ k·∫øt qu·∫£ success/fail r√µ r√†ng.
            
        except Exception as e:
            logging.error(f"[Step 4] L·ªói t·∫°o audio Edge TTS: {e}")
            return False, f"L·ªói TTS: {e}"

    
    # Ki·ªÉm tra k√™t qu·∫£ chung
    if not audio_files:
        return False, "Kh√¥ng t·∫°o ƒë∆∞·ª£c audio n√†o (ho·∫∑c l·ªói to√†n b·ªô)"
    
    logging.info(f"[Step 4] T·ªïng h·ª£p {len(audio_files)} file audio th√†nh c√¥ng")


    # ===== B∆∞·ªõc 4.2: C·∫Øt kho·∫£ng l·∫∑ng ƒë·∫ßu file audio =====
    logging.info(f"[Step 4] ƒêang c·∫Øt kho·∫£ng l·∫∑ng ƒë·∫ßu c√°c file audio...")
    trim_count = 0
    for audio_path, _ in audio_files:
        if os.path.exists(audio_path):
            if trim_silence_from_audio(audio_path):
                trim_count += 1
    logging.info(f"[Step 4] ƒê√£ trim {trim_count}/{len(audio_files)} file audio")
    
    # ===== B∆∞·ªõc 4.3: Scale SRT n·∫øu c·∫ßn =====
    if speed_factor != 1.0:
        scaled_srt = os.path.join(work_dir, "auto", f"translated_subtitle_{speed_factor}x.srt")
        scale_success = scale_srt_timing(srt_input, scaled_srt, speed_factor)
        if scale_success:
            srt_for_merge = scaled_srt
            logging.info(f"[Step 4] ƒê√£ scale SRT v·ªõi factor {speed_factor}x")
        else:
            srt_for_merge = srt_input
    else:
        srt_for_merge = srt_input
    
    # ===== B∆∞·ªõc 4.4: Gh√©p audio (kh√¥ng ph√¢n t√≠ch t·ªëc ƒë·ªô) =====
    try:
        from app.core.tts_funtion import merge_audio_files_ffmpeg
    except ImportError:
        from tts_funtion import merge_audio_files_ffmpeg
    
    # N·∫øu d√πng CapCut, audio_files ƒë√£ ƒë·∫ßy ƒë·ªß.
    # N·∫øu d√πng Edge TTS, audio_files c≈©ng ƒë√£ ƒë·∫ßy ƒë·ªß.
    # Tuy nhi√™n merge_audio_files_ffmpeg ƒë√¥i khi c·∫ßn list ƒë∆∞·ª£c sort.
    
    audio_files.sort(key=lambda x: x[1]) # Sort by start_ms
    
    if not audio_files:
        return False, "Kh√¥ng t√¨m th·∫•y file audio ƒë·ªÉ gh√©p"
    
    logging.info(f"[Step 4] Gh√©p {len(audio_files)} audio files...")
    
    # X√≥a file output c≈© n·∫øu t·ªìn t·∫°i
    if os.path.exists(output_audio):
        try:
            os.remove(output_audio)
        except PermissionError:
            import time
            timestamp = int(time.time())
            output_audio = output_audio.replace(".wav", f"_{timestamp}.wav")
    
    try:
        success = merge_audio_files_ffmpeg(audio_files, output_audio)
        
        if success:
            logging.info(f"[Step 4] ƒê√£ gh√©p audio -> {output_audio}")
            return True, f"ƒê√£ t·∫°o audio: {os.path.basename(output_audio)}"
        else:
            return False, "L·ªói gh√©p audio"
            
    except Exception as e:
        logging.error(f"[Step 4] L·ªói merge audio: {e}")
        return False, f"L·ªói merge: {e}"


def scale_srt_timing(input_path, output_path, factor):
    """Scale timing c·ªßa SRT theo h·ªá s·ªë factor (1.2 = ch·∫≠m l·∫°i 20%)"""
    logging.info(f"Scale SRT timing (x{factor}): {os.path.basename(input_path)}")
    
    def parse_time(time_str):
        h, m, s, ms = map(int, re.split('[:,]', time_str))
        return (h*3600 + m*60 + s) * 1000000 + ms * 1000

    def format_time(micros):
        total_ms = int(micros / 1000)
        ms = total_ms % 1000
        s = (total_ms // 1000) % 60
        m = (total_ms // 60000) % 60
        h = (total_ms // 3600000)
        return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"
    
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()

        pattern = r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})'

        def replace_func(match):
            start_str, end_str = match.groups()
            new_start = parse_time(start_str) * factor
            new_end = parse_time(end_str) * factor
            return f"{format_time(new_start)} --> {format_time(new_end)}"

        new_content = re.sub(pattern, replace_func, content)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        logging.info(f"Scale th√†nh c√¥ng -> {output_path}")
        return True
    except Exception as e:
        logging.error(f"L·ªói scale_srt_timing: {e}")
        return False


def trim_silence_from_audio(input_path, output_path=None):
    """
    C·∫Øt b·ªè kho·∫£ng im l·∫∑ng ƒë·∫ßu file audio b·∫±ng FFmpeg.
    
    Args:
        input_path: ƒê∆∞·ªùng d·∫´n file audio
        output_path: ƒê∆∞·ªùng d·∫´n output (None = ghi ƒë√® file g·ªëc)
    
    Returns:
        bool: True n·∫øu th√†nh c√¥ng
    """
    if output_path is None:
        if input_path.endswith(".wav"):
            temp_path = input_path.replace(".wav", "_temp.wav")
        else:
            temp_path = input_path.replace(".mp3", "_temp.mp3")
    else:
        temp_path = output_path
    
    try:
        # FFmpeg filter: c·∫Øt kho·∫£ng l·∫∑ng ƒë·∫ßu file
        filter_str = "silenceremove=start_periods=1:start_threshold=-50dB"
        
        cmd = [
            'ffmpeg', '-y',
            '-i', input_path,
            '-af', filter_str
        ]
        
        # Codec theo extension
        if input_path.lower().endswith(".wav"):
            cmd.extend(['-c:a', 'pcm_s16le'])
        else:
            cmd.extend(['-c:a', 'libmp3lame', '-b:a', '192k'])

        cmd.append(temp_path)
        
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        # N·∫øu kh√¥ng c√≥ output_path, ghi ƒë√® file g·ªëc
        if output_path is None:
            os.remove(input_path)
            os.rename(temp_path, input_path)
        
        return True
        
    except Exception as e:
        logging.error(f"L·ªói trim silence: {e}")
        if os.path.exists(temp_path) and output_path is None:
            try:
                os.remove(temp_path)
            except:
                pass
        return False


# ========== UTILITY: Extract Text Only from SRT (for translation) ==========
def extract_text_from_srt(srt_path, output_txt_path):
    """Tr√≠ch xu·∫•t text t·ª´ file SRT (kh√¥ng c√≥ timing)"""
    logging.info(f"Extract text from SRT: {os.path.basename(srt_path)}")
    
    try:
        with open(srt_path, "r", encoding="utf-8") as f:
            content = f.read()

        blocks = re.split(r'\n\s*\n', content.strip())
        texts = []

        for block in blocks:
            lines = block.strip().split("\n")
            # T√¨m d√≤ng c√≥ timestamp
            for idx, line in enumerate(lines):
                if "-->" in line:
                    # Text n·∫±m sau d√≤ng timestamp
                    text_lines = lines[idx+1:]
                    if text_lines:
                        texts.append(" ".join(text_lines))
                    break

        with open(output_txt_path, "w", encoding="utf-8") as f:
            for t in texts:
                f.write(t + "\n")

        logging.info(f"Extracted {len(texts)} lines -> {output_txt_path}")
        return True, len(texts)

    except Exception as e:
        logging.error(f"L·ªói extract_text_from_srt: {e}")
        return False, str(e)
