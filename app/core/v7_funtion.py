#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CapCut Functions Module - C√°c h√†m x·ª≠ l√Ω CapCut draft
T√°ch t·ª´ mainv7_0.py ƒë·ªÉ t√°i s·ª≠ d·ª•ng trong CapcutToolv2.py
"""

import json
import uuid
import csv
import re
import os
import logging
from copy import deepcopy
from pathlib import Path
from typing import List, Dict, Any

# Import c√°c h√†m d√πng chung t·ª´ utils
# Import c√°c h√†m d√πng chung t·ª´ utils
try:
    from app.core.utils import (
        load_json_file,
        find_video_track,
        find_audio_tracks,
        find_video_tracks,
        find_text_tracks,
        find_effect_tracks,
        format_timing,
        save_to_csv,
        create_captions_xlsx_if_not_exists,
        split_video_track_by_text_timing,
        get_csv_timing_points,
        export_to_srt,
        milliseconds_to_srt_time,
        _tokenize_caption_words,
        is_chinese,
        export_from_csv,
        export_chinese_from_results,
        export_chinese_with_char_count,
        get_cn_texts,
        extract_text_from_content,
        clean_text_from_html,
    )
except ImportError:
    # Fallback cho tr∆∞·ªùng h·ª£p ch·∫°y tr·ª±c ti·∫øp ho·∫∑c c·∫•u tr√∫c kh√°c
    from utils import (
        load_json_file,
        find_video_track,
        find_audio_tracks,
        find_video_tracks,
        find_text_tracks,
        find_effect_tracks,
        format_timing,
        save_to_csv,
        create_captions_xlsx_if_not_exists,
        split_video_track_by_text_timing,
        get_csv_timing_points,
        export_to_srt,
        milliseconds_to_srt_time,
        _tokenize_caption_words,
        is_chinese,
        export_from_csv,
        export_chinese_from_results,
        export_chinese_with_char_count,
        get_cn_texts,
        extract_text_from_content,
    )


# --- H√†m ph·ª• tr·ª£ cho x·ª≠ l√Ω TEXT (ri√™ng cho version n√†y) ---
# get_cn_texts v√† extract_text_from_content ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang utils.py

# ==============================================================================
# C√ÅC H√ÄM CH·ª®C NƒÇNG CH√çNH
# ==============================================================================


def get_translated_texts_with_timing(json_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    L·∫•y th√¥ng tin text ƒë√£ ƒë∆∞·ª£c translate t·ª´ materials > texts
    Bao g·ªìm text ti·∫øng Vi·ªát v√† timing
    C·∫¢I TI·∫æN: X·ª≠ l√Ω c·∫£ content JSON v√† string th∆∞·ªùng
    """
    results = []

    # L·∫•y subtitle timing t·ª´ extra_info
    subtitle_timings = []
    if (
        "extra_info" in json_data
        and "subtitle_fragment_info_list" in json_data["extra_info"]
    ):
        for fragment in json_data["extra_info"]["subtitle_fragment_info_list"]:
            if "subtitle_cache_info" in fragment and fragment["subtitle_cache_info"]:
                try:
                    cache_info = json.loads(fragment["subtitle_cache_info"])
                    if "sentence_list" in cache_info:
                        for sentence in cache_info["sentence_list"]:
                            if (
                                "bilingual_lan" in sentence
                                and sentence["bilingual_lan"] == "vi-VN"
                            ):
                                start_time = sentence.get("start_time", 0)
                                end_time = sentence.get("end_time", 0)
                                original_text = sentence.get("text", "")
                                translation_text = sentence.get("translation_text", "")

                                subtitle_timings.append(
                                    {
                                        "start_time": start_time,
                                        "end_time": end_time,
                                        "original_text": original_text,
                                        "translation_text": translation_text,
                                    }
                                )
                except:
                    continue

    # L·∫•y text t·ª´ materials > texts
    if "materials" in json_data and "texts" in json_data["materials"]:
        for text_item in json_data["materials"]["texts"]:
            # Ch·ªâ l·∫•y text c√≥ language l√† vi-VN
            if text_item.get("language") == "vi-VN":
                # L·∫•y text t·ª´ content - X·ª¨ L√ù C·∫¢ 2 D·∫†NG
                content = text_item.get("content", "")
                if content.startswith("{") and content.endswith("}"):
                    try:
                        content_data = json.loads(content)
                        text = content_data.get("text", "")
                    except:
                        text = content
                else:
                    text = content

                # L·∫•y text t·ª´ recognize_text n·∫øu c√≥
                recognize_text = text_item.get("recognize_text", "")

                # L·∫•y text t·ª´ base_content n·∫øu c√≥
                base_content = text_item.get("base_content", "")

                # ∆Øu ti√™n text t·ª´ content, sau ƒë√≥ recognize_text, cu·ªëi c√πng base_content
                final_text = text or recognize_text or base_content

                if final_text:
                    # T√¨m timing t∆∞∆°ng ·ª©ng t·ª´ subtitle
                    timing_info = None
                    # L·∫•y timing theo th·ª© t·ª± xu·∫•t hi·ªán
                    if len(results) < len(subtitle_timings):
                        timing_info = subtitle_timings[len(results)]

                    # L·∫•y timing t·ª´ current_words n·∫øu c√≥
                    current_words = text_item.get("current_words", {})
                    start_times = current_words.get("start_time", [])
                    end_times = current_words.get("end_time", [])

                    result = {
                        "text": final_text,
                        "language": text_item.get("language", ""),
                        "id": text_item.get("id", ""),
                        "group_id": text_item.get("group_id", ""),
                        "timing_from_subtitle": timing_info,
                        "timing_from_current_words": (
                            {"start_times": start_times, "end_times": end_times}
                            if start_times or end_times
                            else None
                        ),
                        "font_size": text_item.get("font_size", 0),
                        "text_color": text_item.get("text_color", ""),
                        "alignment": text_item.get("alignment", 0),
                    }

                    results.append(result)

    return results


# format_timing ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang utils.py


def print_results(results: List[Dict[str, Any]]):
    """In k·∫øt qu·∫£ ra m√†n h√¨nh"""
    print(f"T√¨m th·∫•y {len(results)} text ƒë√£ ƒë∆∞·ª£c translate:\n")
    print("=" * 80)

    for i, result in enumerate(results, 1):
        print(f"\n{i}. Text ID: {result['id']}")
        print(f"   Group ID: {result['group_id']}")
        print(f"   Text: {result['text']}")
        print(f"   Language: {result['language']}")
        print(f"   Font Size: {result['font_size']}")
        print(f"   Text Color: {result['text_color']}")
        print(f"   Alignment: {result['alignment']}")

        # Timing t·ª´ subtitle
        if result["timing_from_subtitle"]:
            timing = result["timing_from_subtitle"]
            start_time = format_timing(timing["start_time"])
            end_time = format_timing(timing["end_time"])
            print(f"   Timing (t·ª´ subtitle): {start_time} - {end_time}")
            print(f"   Original text: {timing['original_text']}")
            if timing["translation_text"]:
                print(f"   Translation text: {timing['translation_text']}")

        # Timing t·ª´ current_words
        if result["timing_from_current_words"]:
            timing = result["timing_from_current_words"]
            if timing["start_times"] and timing["end_times"]:
                print(f"   Timing (t·ª´ current_words):")
                for j, (start, end) in enumerate(
                    zip(timing["start_times"], timing["end_times"])
                ):
                    start_time = format_timing(start)
                    end_time = format_timing(end)
                    print(f"     Word {j+1}: {start_time} - {end_time}")

        print("-" * 80)


# save_to_csv ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang utils.py

# ==============================================================================
# C·∫§U H√åNH STYLE ƒê∆Ø·ª¢C NH√öNG TR·ª∞C TI·∫æP T·ª™ DRAFT_CONTENT_FIX.JSON
# ==============================================================================


def get_hardcoded_style_config() -> Dict[str, Any]:
    """
    Tr·∫£ v·ªÅ c·∫•u h√¨nh style ƒë√£ ƒë∆∞·ª£c sao ch√©p ch√≠nh x√°c t·ª´ file m·∫´u th√†nh c√¥ng.
    C·∫¨P NH·∫¨T: S·ª≠ d·ª•ng c·∫•u tr√∫c th·ª±c t·∫ø t·ª´ saukhisuastyle.json
    """
    return {
        "text_style_template": {
            "add_type": 0,
            "alignment": 1,
            "background_alpha": 1.0,
            "background_color": "#000000",
            "background_fill": "",
            "background_height": 0.14,
            "background_horizontal_offset": 0.0,
            "background_round_radius": 0.0,
            "background_style": 0,
            "background_vertical_offset": 0.0,
            "background_width": 0.14,
            "base_content": "",
            "bold_width": 0.0,
            "border_alpha": 1.0,
            "border_color": "#ffffff",
            "border_width": 0.08,
            "caption_template_info": {
                "category_id": "",
                "category_name": "",
                "effect_id": "",
                "is_new": False,
                "path": "",
                "request_id": "",
                "resource_id": "",
                "resource_name": "",
                "source_platform": 0,
                "third_resource_id": "",
            },
            "check_flag": 47,
            "combo_info": {"text_templates": []},
            "cutoff_postfix": "",
            "enable_path_typesetting": False,
            "fixed_height": -1.0,
            "fixed_width": -1.0,
            "font_category_id": "",
            "font_category_name": "",
            "font_id": "",
            "font_name": "",
            "font_path": "C:/Users/congt/AppData/Local/CapCut/User Data/Cache/effect/7535354391860120848/864dc8c9046e5845640daba0bdeab144/font.ttf",
            "font_resource_id": "7535354391860120848",
            "font_size": 8.0,  # ‚úÖ ƒê√É X√ÅC NH·∫¨N: 8.0
            "font_source_platform": 1,
            "font_team_id": "",
            "font_third_resource_id": "",
            "font_title": "none",  # ‚úÖ ƒê√É X√ÅC NH·∫¨N: "none" t·ª´ file m·∫´u
            "font_url": "",
            "force_apply_line_max_width": False,
            "global_alpha": 1.0,
            "has_shadow": False,
            "initial_scale": 1.0,
            "inner_padding": -1.0,
            "is_lyric_effect": False,
            "is_rich_text": False,
            "is_words_linear": False,
            "italic_degree": 0,
            "ktv_color": "",
            "language": "vi-VN",
            "layer_weight": 1,
            "letter_spacing": 0.0,
            "line_feed": 1,
            "line_max_width": 0.82,
            "line_spacing": 0.02,
            "lyric_group_id": "",
            "lyrics_template": {
                "category_id": "",
                "category_name": "",
                "effect_id": "",
                "panel": "",
                "path": "",
                "request_id": "",
                "resource_id": "",
                "resource_name": "",
            },
            "multi_language_current": "none",
            "name": "",
            "offset_on_path": 0.0,
            "oneline_cutoff": False,
            "operation_type": 0,
            "original_size": [],
            "preset_category": "",
            "preset_category_id": "",
            "preset_has_set_alignment": False,
            "preset_id": "",
            "preset_index": 0,
            "preset_name": "",
            "recognize_task_id": "",
            "recognize_type": 0,
            "relevance_segment": [],
            "shadow_alpha": 0.9,
            "shadow_angle": -45.0,
            "shadow_color": "#000000",
            "shadow_distance": 5.0,
            "shadow_point": {"x": 0.6363961030678928, "y": -0.6363961030678928},
            "shadow_smoothing": 0.45,
            "shape_clip_x": False,
            "shape_clip_y": False,
            "source_from": "",
            "ssml_content": "",
            "style_name": "",
            "sub_template_id": -1,
            "sub_type": 5,
            "subtitle_keywords": None,
            "subtitle_keywords_config": None,
            "subtitle_template_original_fontsize": 0.0,
            "text_alpha": 1.0,
            "text_color": "#ffffff",
            "text_curve": None,
            "text_exceeds_path_process_type": 0,
            "text_loop_on_path": False,
            "text_preset_resource_id": "",
            "text_size": 30,
            "text_to_audio_ids": [],
            "text_typesetting_path_index": 0,
            "text_typesetting_paths": None,
            "text_typesetting_paths_file": "",
            "translate_original_text": "",
            "tts_auto_update": False,
            "type": "subtitle",  # QUAN TR·ªåNG: S·ª≠ d·ª•ng "subtitle" thay v√¨ "text"
            "typesetting": 0,
            "underline": False,
            "underline_offset": 0.22,
            "underline_width": 0.05,
            "use_effect_default_color": True,
        },
        "font_template": {
            "category_id": "favoured",
            "category_name": "Y√™u th√≠ch",
            "effect_id": "7535354391860120848",
            "file_uri": "",
            "id": "470A81BA-465E-4a20-992C-C4FEFA0E296C",  # ID t·ª´ file m·∫´u
            "path": "C:/Users/congt/AppData/Local/CapCut/User Data/Cache/effect/7535354391860120848/864dc8c9046e5845640daba0bdeab144/font.ttf",
            "request_id": "",
            "resource_id": "7535354391860120848",
            "source_platform": 1,
            "team_id": "",
            "third_resource_id": "",
            "title": "Ti·∫øng Vi·ªát",  # ‚úÖ ƒê√É X√ÅC NH·∫¨N: "Ti·∫øng Vi·ªát"
        },
        "content_styles_template": {
            "styles": [
                {
                    "fill": {
                        "alpha": 1.0,
                        "content": {
                            "render_type": "solid",
                            "solid": {"alpha": 1.0, "color": [1.0, 1.0, 1.0]},
                        },
                    },
                    "font": {
                        "id": "7535354391860120848",
                        "path": "C:/Users/congt/AppData/Local/CapCut/User Data/Cache/effect/7535354391860120848/864dc8c9046e5845640daba0bdeab144/font.ttf",
                    },
                    "range": [0, 0],  # S·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t theo ƒë·ªô d√†i text
                    "shadows": [
                        {
                            "alpha": 1.0,
                            "angle": 0.0,
                            "content": {
                                "render_type": "solid",
                                "solid": {"alpha": 1.0, "color": [0.0, 0.0, 0.0]},
                            },
                            "diffuse": 0.0833333358168602,
                            "distance": 0.0,
                            "feather": 0.15,
                        }
                    ],
                    "size": 8,
                    "useLetterColor": True,
                }
            ],
            "text": "",  # S·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t v·ªõi n·ªôi dung th·ª±c t·∫ø
        },
    }


def apply_style_to_texts(data_to_update: Dict) -> bool:
    """
    √Åp d·ª•ng style ƒë√£ ƒë∆∞·ª£c nh√∫ng v√†o T·∫§T C·∫¢ text vi-VN trong draft.
    C·∫¨P NH·∫¨T: √Åp d·ª•ng cho to√†n b·ªô text c·ªßa t·∫•t c·∫£ c√°c track text, kh√¥ng ch·ªâ ri√™ng vi-VN.
    """
    style_config = get_hardcoded_style_config()
    text_template = style_config["text_style_template"]
    font_template = style_config["font_template"]
    content_styles_template = style_config["content_styles_template"]

    # C·∫≠p nh·∫≠t fonts trong materials
    materials = data_to_update.setdefault("materials", {})
    fonts = materials.setdefault("fonts", [])

    if not fonts:
        fonts.append(font_template)
        logging.info(f"‚úÖ ƒê√£ th√™m font '{font_template['title']}' v√†o materials.")
    else:
        # Ki·ªÉm tra xem font ƒë√£ t·ªìn t·∫°i ch∆∞a
        font_exists = any(f.get("id") == font_template["id"] for f in fonts)
        if not font_exists:
            fonts.append(font_template)
            logging.info(f"‚úÖ ƒê√£ th√™m font '{font_template['title']}' v√†o materials.")

    # L·∫•y danh s√°ch T·∫§T C·∫¢ text (kh√¥ng ch·ªâ vi-VN)
    texts = materials.get("texts", [])

    if not texts:
        logging.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y text n√†o ƒë·ªÉ √°p d·ª•ng style.")
        return False

    # T·∫°o m·ªôt danh s√°ch m·ªõi ƒë·ªÉ ch·ª©a c√°c text ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p
    new_styled_texts = []

    for text_item in texts:
        # √Åp d·ª•ng style cho T·∫§T C·∫¢ text
        # 1. Gi·ªØ l·∫°i c√°c th√¥ng tin g·ªëc quan tr·ªçng
        original_id = text_item.get("id")
        original_group_id = text_item.get("group_id")
        original_language = text_item.get("language", "")

        # L·∫•y n·ªôi dung text t·ª´ c·∫£ 2 d·∫°ng (string th∆∞·ªùng ho·∫∑c JSON string)
        content_str = text_item.get("content", "")
        if content_str.startswith("{") and content_str.endswith("}"):
            try:
                content_data = json.loads(content_str)
                original_text_content = content_data.get("text", "")
            except:
                original_text_content = content_str
        else:
            original_text_content = content_str

        # 2. T·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng text m·ªõi t·ª´ template
        new_text_obj = deepcopy(text_template)

        # 3. T·∫°o content m·ªõi v·ªõi c·∫•u tr√∫c styles ph·ª©c t·∫°p
        new_content_styles = deepcopy(content_styles_template)
        new_content_styles["text"] = original_text_content
        # C·∫≠p nh·∫≠t range theo ƒë·ªô d√†i text
        text_length = len(original_text_content)
        new_content_styles["styles"][0]["range"] = [0, text_length]

        # 4. ƒêi·ªÅn l·∫°i th√¥ng tin g·ªëc v√†o ƒë·ªëi t∆∞·ª£ng m·ªõi
        new_text_obj["id"] = original_id
        new_text_obj["group_id"] = original_group_id
        new_text_obj["language"] = original_language  # Gi·ªØ nguy√™n ng√¥n ng·ªØ g·ªëc
        new_text_obj["content"] = json.dumps(new_content_styles, ensure_ascii=False)
        new_text_obj["recognize_text"] = original_text_content
        new_text_obj.setdefault("words", {})["text"] = _tokenize_caption_words(
            original_text_content
        )
        new_text_obj["fonts"] = [deepcopy(font_template)]

        # 5. Th√™m ƒë·ªëi t∆∞·ª£ng ƒë√£ n√¢ng c·∫•p v√†o danh s√°ch m·ªõi
        new_styled_texts.append(new_text_obj)

    # 6. Thay th·∫ø to√†n b·ªô danh s√°ch text c≈© b·∫±ng danh s√°ch m·ªõi ƒë√£ n√¢ng c·∫•p
    materials["texts"] = new_styled_texts

    logging.info(f"‚úÖ ƒê√£ √°p d·ª•ng style th√†nh c√¥ng cho {len(texts)} text (t·∫•t c·∫£ ng√¥n ng·ªØ).")
    return True


# create_captions_xlsx_if_not_exists ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang utils.py


# export_chinese_from_results, export_chinese_with_char_count, export_to_srt, export_from_csv ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang utils.py
# C√°c h√†m n√†y ƒë√£ ƒë∆∞·ª£c import t·ª´ utils.py ·ªü ƒë·∫ßu file


def replace_vi_texts_in_draft_from_xlsx(
    draft_path: str,
    xlsx_path: str,
    sheet: str | None = None,
    column: str = "B",
    start_row: int = 2,
    offset: int = 0,
    map_by_index: bool = True,
) -> bool:
    """
    ƒê·ªçc c√°c caption t·ª´ file Excel (m·∫∑c ƒë·ªãnh c·ªôt B) v√† thay th·∫ø tu·∫ßn t·ª± v√†o
    materials > texts (language = vi-VN) trong draft_content.json.
    """
    if not os.path.isfile(draft_path):
        logging.error(f"Kh√¥ng t√¨m th·∫•y file draft: {draft_path}")
        return False
    if not os.path.isfile(xlsx_path):
        logging.error(f"Kh√¥ng t√¨m th·∫•y file Excel: {xlsx_path}")
        return False

    try:
        from openpyxl import load_workbook  # type: ignore
    except Exception:
        logging.error("Thi·∫øu th∆∞ vi·ªán openpyxl. H√£y c√†i ƒë·∫∑t: pip install openpyxl")
        return False

    # ƒê·ªçc JSON draft
    try:
        with open(draft_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception as e:
        logging.error(f"L·ªói khi ƒë·ªçc JSON: {e}")
        return False

    # ƒê·ªçc Excel
    try:
        wb = load_workbook(filename=xlsx_path, read_only=True, data_only=True)
        ws = wb[sheet] if sheet else wb[wb.sheetnames[0]]
    except Exception as e:
        logging.error(f"L·ªói khi ƒë·ªçc Excel: {e}")
        return False

    # Thu th·∫≠p d√≤ng t·ª´ c·ªôt ch·ªâ ƒë·ªãnh
    col_letter = (column or "B").strip() or "B"
    try:
        from openpyxl.utils import column_index_from_string  # type: ignore

        col_idx = int(column_index_from_string(col_letter))
    except Exception:
        logging.error(f"C·ªôt kh√¥ng h·ª£p l·ªá: {column}")
        return False

    if start_row < 1:
        start_row = 1

    new_lines: list[str] = []
    try:
        max_row = ws.max_row or 0
        for r in range(start_row, max_row + 1):
            cell = ws.cell(row=r, column=col_idx)
            val = cell.value
            text_val = "" if val is None else str(val)
            clean = text_val.replace("\r", " ").replace("\n", " ").strip()
            if clean:
                new_lines.append(clean)
    except Exception as e:
        logging.error(f"L·ªói khi duy·ªát c·ªôt Excel: {e}")
        return False

    # Th·ª±c hi·ªán thay th·∫ø theo ch·ªâ s·ªë (materials > texts > 0..n) nh∆∞ y√™u c·∫ßu
    materials = data.get("materials") or {}
    texts = materials.get("texts") or []
    if not isinstance(texts, list) or not texts:
        logging.warning("Kh√¥ng t√¨m th·∫•y materials > texts trong draft ho·∫∑c danh s√°ch r·ªóng")
        return False

    if offset < 0:
        offset = 0
    if map_by_index:
        start_index = offset
        pair_count = min(len(texts) - start_index, len(new_lines))
        index_resolver = lambda i: start_index + i
    else:
        vi_indexes = []
        for idx, t in enumerate(texts):
            if isinstance(t, dict) and (t.get("language") or "").strip() == "vi-VN":
                vi_indexes.append(idx)
        if not vi_indexes:
            logging.warning("Kh√¥ng t√¨m th·∫•y texts vi-VN ƒë·ªÉ thay th·∫ø")
            return False
        vi_slice = vi_indexes[offset:]
        pair_count = min(len(vi_slice), len(new_lines))
        index_resolver = lambda i: vi_slice[i]
    if pair_count == 0:
        logging.warning("Excel kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ thay th·∫ø")
        return False


    updates = 0
    for i in range(pair_count):
        idx = index_resolver(i)
        t = texts[idx] if 0 <= idx < len(texts) else None
        if not isinstance(t, dict):
            continue
        new_text = new_lines[i]

        content_val = t.get("content")
        updated_content = None
        if isinstance(content_val, str) and content_val:
            try:
                parsed = json.loads(content_val)
                if isinstance(parsed, dict):
                    parsed["text"] = new_text
                    updated_content = json.dumps(parsed, ensure_ascii=False)
            except Exception:
                updated_content = new_text
        else:
            updated_content = new_text

        t["content"] = updated_content
        t["recognize_text"] = new_text

        # C·∫≠p nh·∫≠t words theo y√™u c·∫ßu
        words_obj = t.get("words")
        if not isinstance(words_obj, dict):
            words_obj = {}
            t["words"] = words_obj
        words_obj["text"] = _tokenize_caption_words(new_text)
        words_obj["start_time"] = []
        words_obj["end_time"] = []

        updates += 1

    data.setdefault("materials", {})["texts"] = texts

    # Backup
    try:
        if os.path.isfile(draft_path):
            bak_path = draft_path + ".bak"
            with open(draft_path, "r", encoding="utf-8") as f_in, open(
                bak_path, "w", encoding="utf-8"
            ) as f_out:
                f_out.write(f_in.read())
            logging.info(f"ƒê√£ t·∫°o backup: {bak_path}")
    except Exception as e:
        logging.warning(f"C·∫£nh b√°o: kh√¥ng th·ªÉ t·∫°o backup: {e}")

    logging.info(
        f"ƒê√£ chu·∫©n b·ªã c·∫≠p nh·∫≠t {updates} texts trong draft t·ª´ Excel (offset={offset}, by_index={map_by_index})"
    )
    if len(new_lines) > pair_count:
        logging.info(
            f"L∆∞u √Ω: c√≤n {len(new_lines) - pair_count} d√≤ng trong Excel ch∆∞a d√πng (v∆∞·ª£t s·ªë l∆∞·ª£ng texts vi-VN)"
        )

    # L∆∞u file v·ªõi n·ªôi dung ƒë√£ c·∫≠p nh·∫≠t (KH√îNG √°p d·ª•ng style)
    try:
        with open(draft_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        logging.info(f"‚úÖ ƒê√£ l∆∞u file v√†o: {draft_path}")
        return True
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi l∆∞u file {draft_path}: {e}")
        return False


def get_srt_timing_points(srt_file: str) -> List[int]:
    """
    ƒê·ªçc file SRT v√† tr·∫£ v·ªÅ danh s√°ch th·ªùi gian b·∫Øt ƒë·∫ßu (ms) c·ªßa t·ª´ng subtitle.
    """
    timing_points = []
    try:
        with open(srt_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # T√°ch c√°c entry SRT (m·ªói entry b·∫Øt ƒë·∫ßu b·∫±ng s·ªë, k·∫øt th√∫c b·∫±ng d√≤ng tr·ªëng)
        entries = content.strip().split('\n\n')
        
        for entry in entries:
            lines = entry.strip().split('\n')
            if len(lines) >= 2:
                # D√≤ng th·ª© 2 l√† timing: "00:00:01,000 --> 00:00:05,000"
                timing_line = lines[1]
                if '-->' in timing_line:
                    start_str = timing_line.split('-->')[0].strip()
                    # Chuy·ªÉn "00:00:01,000" th√†nh ms
                    start_ms = time_to_ms_srt(start_str)
                    timing_points.append(start_ms)
    except Exception as e:
        print(f"L·ªói khi ƒë·ªçc file SRT: {e}")
    
    return timing_points


def time_to_ms_srt(time_str: str) -> int:
    """
    Chuy·ªÉn th·ªùi gian SRT "HH:MM:SS,mmm" th√†nh mili gi√¢y.
    """
    try:
        h, m, s_ms = time_str.split(':')
        s, ms = s_ms.split(',')
        return int(h) * 3600000 + int(m) * 60000 + int(s) * 1000 + int(ms)
    except:
        return 0


def split_video_by_srt_timing(
    json_data: Dict[str, Any], srt_file: str
):
    """CH·ª®C NƒÇNG: Chia video d·ª±a tr√™n th·ªùi gian t·ª´ file SRT"""
    timing_points = get_srt_timing_points(srt_file)
    if not timing_points:
        logging.warning("Kh√¥ng c√≥ th√¥ng tin timing t·ª´ file SRT ƒë·ªÉ chia video.")
        return False

    tracks = json_data.get("tracks", [])
    video_track = find_video_track(tracks)
    if not video_track:
        logging.warning("Kh√¥ng t√¨m th·∫•y video track.")
        return False

    logging.info(f"S·ªë ƒëi·ªÉm chia video t·ª´ SRT: {len(timing_points)}")

    backup_path = Path("draft_content.json.bak")
    if Path("draft_content.json").exists():
        backup_path.write_text(
            Path("draft_content.json").read_text(encoding="utf-8"), encoding="utf-8"
        )
        logging.info(f"ƒê√£ t·∫°o backup: {backup_path}")

    split_video_track_by_text_timing(video_track, timing_points)

    with open("draft_content.json", "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=4)

    logging.info("ƒê√£ c·∫≠p nh·∫≠t draft_content.json v·ªõi video ƒë√£ ƒë∆∞·ª£c chia.")
    return True


def split_texts_into_multiple_tracks_by_character_index(
    json_data: Dict[str, Any], xlsx_file: str = "captions.xlsx"
) -> bool:
    """
    Ph√¢n chia c√°c text segments hi·ªán c√≥ th√†nh nhi·ªÅu track m·ªõi
    d·ª±a tr√™n ch·ªâ s·ªë nh√¢n v·∫≠t trong c·ªôt 'Ph√¢n chia nh√¢n v·∫≠t' t·ª´ file Excel.
    """
    logging.info(f"\n--- CH·ª®C NƒÇNG: CHIA TEXT TH√ÄNH NHI·ªÄU TRACK THEO NH√ÇN V·∫¨T ---")

    if not os.path.isfile(xlsx_file):
        logging.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file Excel: {xlsx_file}")
        return False

    try:
        from openpyxl import load_workbook
    except ImportError:
        logging.error("‚ùå Thi·∫øu th∆∞ vi·ªán openpyxl. H√£y c√†i ƒë·∫∑t: pip install openpyxl")
        return False

    # 1. ƒê·ªçc d·ªØ li·ªáu t·ª´ Excel
    try:
        wb = load_workbook(filename=xlsx_file, read_only=True, data_only=True)
        ws = wb.active
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi ƒë·ªçc Excel: {e}")
        return False

    # Thu th·∫≠p d·ªØ li·ªáu t·ª´ c·ªôt C (Ph√¢n chia nh√¢n v·∫≠t)
    character_indices = []
    try:
        max_row = ws.max_row or 0
        for r in range(2, max_row + 1):  # B·∫Øt ƒë·∫ßu t·ª´ d√≤ng 2
            cell = ws.cell(row=r, column=3)  # C·ªôt C
            val = cell.value
            char_index_str = "" if val is None else str(val).strip()

            try:
                char_index = int(char_index_str) if char_index_str else 0
            except ValueError:
                char_index = 0  # Kh√¥ng ph·∫£i s·ªë, x·∫øp v√†o nh√≥m 0

            character_indices.append(char_index)
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi ƒë·ªçc c·ªôt ph√¢n chia nh√¢n v·∫≠t: {e}")
        return False

    # 2. Thu th·∫≠p c√°c text segment hi·ªán c√≥ t·ª´ draft
    tracks = json_data.get("tracks", [])
    existing_text_tracks = find_text_tracks(tracks)

    if not existing_text_tracks or not existing_text_tracks[0].get("segments"):
        logging.warning("‚ùå Kh√¥ng t√¨m th·∫•y track text n√†o trong draft ƒë·ªÉ ph√¢n chia.")
        return False

    original_segments = existing_text_tracks[0]["segments"]

    if len(original_segments) != len(character_indices):
        logging.warning(
            f"‚ö†Ô∏è C·∫£nh b√°o: S·ªë l∆∞·ª£ng text segment ({len(original_segments)}) v√† s·ªë d√≤ng Excel ({len(character_indices)}) kh√¥ng kh·ªõp."
        )
        logging.warning(
            f"   Ch·ªâ x·ª≠ l√Ω t·ªëi ƒëa {min(len(original_segments), len(character_indices))} segments."
        )
        max_map = min(len(original_segments), len(character_indices))
    else:
        max_map = len(original_segments)

    # 3. Ph√¢n lo·∫°i segments theo ch·ªâ s·ªë nh√¢n v·∫≠t
    character_tracks: Dict[int, List[Dict[str, Any]]] = {}

    for i in range(max_map):
        char_index = character_indices[i]
        segment = original_segments[i]

        # Nh√≥m c√°c segment theo ch·ªâ s·ªë nh√¢n v·∫≠t
        character_tracks.setdefault(char_index, []).append(segment)

    if not character_tracks:
        logging.warning("‚ö†Ô∏è Kh√¥ng c√≥ text n√†o ƒë·ªÉ ph√¢n chia.")
        return False

    # 4. X√¢y d·ª±ng l·∫°i danh s√°ch tracks
    new_tracks = [t for t in tracks if t.get("type") != "text"]

    # T·∫°o track m·ªõi cho m·ªói nh√¢n v·∫≠t
    all_char_indices = sorted(character_tracks.keys())

    for char_index in all_char_indices:
        segments = character_tracks[char_index]

        # S·∫Øp x·∫øp l·∫°i segments theo th·ªùi gian b·∫Øt ƒë·∫ßu
        segments.sort(key=lambda s: s.get("target_timerange", {}).get("start", 0))

        # T·∫°o t√™n track
        if char_index == 0:
            track_name = "Text-Other"
        else:
            track_name = f"Text-Char-{char_index}"

        # ƒê√°nh l·∫°i track_render_index
        for i, seg in enumerate(segments):
            seg["track_render_index"] = i

        # T·∫°o track m·ªõi
        new_text_track = deepcopy(existing_text_tracks[0])
        new_text_track["id"] = str(uuid.uuid4()).upper()
        new_text_track["segments"] = segments
        new_text_track["flag"] = 0

        new_tracks.append(new_text_track)
        logging.info(f"‚úÖ ƒê√£ t·∫°o track '{track_name}' v·ªõi {len(segments)} segments.")

    # 5. C·∫≠p nh·∫≠t draft
    json_data["tracks"] = new_tracks

    # T·∫°o backup tr∆∞·ªõc khi l∆∞u
    backup_path = "draft_content.json.bak"
    try:
        if os.path.exists("draft_content.json"):
            if os.path.exists(backup_path):
                os.remove(backup_path)
            os.rename("draft_content.json", backup_path)
            logging.info(f"üíæ ƒê√£ t·∫°o backup: {backup_path}")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng th·ªÉ t·∫°o backup: {e}")

    # L∆∞u file
    try:
        with open("draft_content.json", "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=4)
        logging.info(
            f"‚úÖ ƒê√£ l∆∞u file 'draft_content.json' v·ªõi c√°c track text ƒë√£ ƒë∆∞·ª£c ph√¢n chia."
        )
        return True
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi l∆∞u file: {e}")
        return False


def split_video_and_slow_down_for_audio(
    json_data: Dict[str, Any], video_start_index: int = 0
) -> bool:
    """CH·ª®C NƒÇNG 2: ƒê·ªìng b·ªô, l√†m ch·∫≠m video theo audio v√† t√°i x√¢y d·ª±ng timeline.

    LOGIC TEXT TIMING:
    - Th·ªùi gian b·∫Øt ƒë·∫ßu text = th·ªùi gian b·∫Øt ƒë·∫ßu audio hi·ªán t·∫°i
    - Th·ªùi gian k·∫øt th√∫c text = th·ªùi gian b·∫Øt ƒë·∫ßu audio ti·∫øp theo
    - Text cu·ªëi c√πng s·∫Ω c√≥ th·ªùi gian k·∫øt th√∫c = th·ªùi gian k·∫øt th√∫c audio cu·ªëi c√πng
    """
    tracks = json_data.get("tracks", [])
    if not tracks:
        logging.error("‚ùå Kh√¥ng t√¨m th·∫•y tracks trong file.")
        return False

    if "materials" not in json_data:
        json_data["materials"] = {}
    if "speeds" not in json_data["materials"]:
        json_data["materials"]["speeds"] = []

    materials = json_data["materials"]
    all_speeds_map = {s["id"]: s for s in materials.get("speeds", [])}

    def get_start_time(seg):
        return int(seg.get("target_timerange", {}).get("start", float("inf")))

    all_video_segments = sorted(
        [
            seg
            for track in find_video_tracks(tracks)
            for seg in track.get("segments", [])
        ],
        key=get_start_time,
    )
    all_audio_segments = sorted(
        [
            seg
            for track in find_audio_tracks(tracks)
            for seg in track.get("segments", [])
        ],
        key=get_start_time,
    )
    all_text_segments = sorted(
        [
            seg
            for track in find_text_tracks(tracks)
            for seg in track.get("segments", [])
        ],
        key=get_start_time,
    )

    all_effect_tracks = find_effect_tracks(tracks)
    effect_material_id = None
    if all_effect_tracks and all_effect_tracks[0].get("segments"):
        effect_material_id = all_effect_tracks[0]["segments"][0].get("material_id")

    if not all_video_segments:
        logging.error("‚ùå Kh√¥ng t√¨m th·∫•y video segment n√†o.")
        return False
    if video_start_index >= len(all_video_segments):
        logging.error(
            f"‚ùå L·ªói: B·∫°n mu·ªën b·∫Øt ƒë·∫ßu t·ª´ video s·ªë {video_start_index + 1}, nh∆∞ng ch·ªâ c√≥ {len(all_video_segments)} video."
        )
        return False

    final_video_segs, final_audio_segs, final_text_segs, final_effect_segs = (
        [],
        [],
        [],
        [],
    )
    cursor_us = get_start_time(all_video_segments[0]) if all_video_segments else 0
    logging.info(f"Timeline s·∫Ω ƒë∆∞·ª£c x√¢y d·ª±ng l·∫°i b·∫Øt ƒë·∫ßu t·ª´ m·ªëc: {cursor_us / 1000:.0f}ms")

    sync_count = min(
        len(all_video_segments) - video_start_index, len(all_audio_segments)
    )
    video_cursor = 0

    for i in range(video_start_index):
        video_seg = deepcopy(all_video_segments[i])
        video_seg["target_timerange"]["start"] = cursor_us
        duration = int(video_seg.get("target_timerange", {}).get("duration", 0))
        cursor_us += duration
        final_video_segs.append(video_seg)
        video_cursor += 1

    logging.info(f"T√¨m th·∫•y {sync_count} c·∫∑p video-audio ƒë·ªÉ ƒë·ªìng b·ªô...")
    for i in range(sync_count):
        video_seg = deepcopy(all_video_segments[video_cursor])
        audio_seg = deepcopy(all_audio_segments[i])
        text_seg = (
            deepcopy(all_text_segments[i]) if i < len(all_text_segments) else None
        )
        source_duration_us = int(
            video_seg.get("source_timerange", {}).get("duration", 0)
        )
        if source_duration_us == 0:
            source_duration_us = int(
                video_seg.get("target_timerange", {}).get("duration", 0)
            )

        audio_duration_us = int(
            audio_seg.get("target_timerange", {}).get("duration", 0)
        )
        final_video_duration_us = source_duration_us
        new_speed = 1.0

        # S·ª¨A L·ªñI: Ch·ªâ l√†m ch·∫≠m video khi audio d√†i h∆°n video
        # Kh√¥ng l√†m nhanh video khi audio ng·∫Øn h∆°n
        if audio_duration_us > source_duration_us and source_duration_us > 0:
            new_speed = float(source_duration_us) / float(audio_duration_us)
            new_speed = max(0.1, new_speed)
            final_video_duration_us = audio_duration_us
            logging.info(
                f"üîπ Video {video_cursor + 1} ƒë∆∞·ª£c l√†m ch·∫≠m th√†nh {audio_duration_us/1000000:.2f}s (t·ªëc ƒë·ªô: {new_speed:.3f}x)"
            )
        else:
            # Gi·ªØ nguy√™n t·ªëc ƒë·ªô v√† th·ªùi l∆∞·ª£ng video khi audio kh√¥ng d√†i h∆°n
            logging.info(
                f"üîπ Video {video_cursor + 1} gi·ªØ nguy√™n t·ªëc ƒë·ªô (audio: {audio_duration_us/1000000:.2f}s, video: {source_duration_us/1000000:.2f}s)"
            )

        video_seg["speed"] = new_speed
        video_seg["target_timerange"]["start"] = cursor_us
        video_seg["target_timerange"]["duration"] = final_video_duration_us
        if "render_timerange" in video_seg:
            video_seg["render_timerange"] = {"start": 0, "duration": 0}

        # THAY ƒê·ªîI LOGIC CU·ªêI C√ôNG: Lu√¥n t·∫°o m·ªõi speed material
        existing_speed_material_id = next(
            (
                ref_id
                for ref_id in video_seg.get("extra_material_refs", [])
                if ref_id in all_speeds_map
            ),
            None,
        )

        # G·ª° b·ªè li√™n k·∫øt c≈© (n·∫øu c√≥) ƒë·ªÉ l√†m s·∫°ch
        if existing_speed_material_id and "extra_material_refs" in video_seg:
            video_seg["extra_material_refs"].remove(existing_speed_material_id)

        # N·∫øu t·ªëc ƒë·ªô kh√¥ng ph·∫£i 1.0, LU√îN T·∫†O M·ªöI speed material v√† li√™n k·∫øt l·∫°i
        if new_speed != 1.0:
            new_speed_material = {
                "id": str(uuid.uuid4()).upper(),
                "speed": new_speed,
                "type": "speed",
                "curve_speed": None,
                "mode": 0,
            }
            materials["speeds"].append(new_speed_material)
            all_speeds_map[new_speed_material["id"]] = new_speed_material
            if "extra_material_refs" not in video_seg:
                video_seg["extra_material_refs"] = []
            video_seg["extra_material_refs"].append(new_speed_material["id"])

        final_video_segs.append(video_seg)
        audio_seg["target_timerange"]["start"] = cursor_us
        audio_seg["target_timerange"]["duration"] = audio_duration_us
        final_audio_segs.append(audio_seg)

        # X·ª¨ L√ù TEXT: To√†n b·ªô text b√°m audio (b·∫Øt ƒë·∫ßu = audio start, k·∫øt th√∫c = audio end)
        if text_seg:
            text_seg["target_timerange"]["start"] = cursor_us
            text_seg["target_timerange"]["duration"] = audio_duration_us
            final_text_segs.append(text_seg)
            logging.info(
                f"üîπ Text {i + 1}: {cursor_us/1000000:.2f}s - {(cursor_us + audio_duration_us)/1000000:.2f}s (duration: {audio_duration_us/1000000:.2f}s)"
            )

        # X·ª¨ L√ù EFFECT: ƒê·ªìng b·ªô theo audio, n·∫øu c√≥ audio ti·∫øp theo c√≤n d∆∞ th√¨ c·ªông th√™m 0.2s
        if effect_material_id:
            effect_duration_us = audio_duration_us

            # Ki·ªÉm tra xem c√≥ audio ti·∫øp theo v√† c√≤n d∆∞ kh√¥ng
            if i + 1 < len(all_audio_segments):
                next_audio_seg = all_audio_segments[i + 1]
                next_audio_duration = int(
                    next_audio_seg.get("target_timerange", {}).get("duration", 0)
                )

                # N·∫øu audio ti·∫øp theo c√≥ duration > 0 (c√≤n d∆∞), c·ªông th√™m 0.2s v√†o effect
                if next_audio_duration > 0:
                    extra_duration_us = 200000  # 0.2 gi√¢y = 200000 microseconds
                    effect_duration_us += extra_duration_us
                    logging.info(
                        f"üîπ Effect {i + 1}: ƒê√£ c·ªông th√™m 0.2s (duration: {effect_duration_us/1000000:.2f}s)"
                    )

            new_effect_seg = {
                "id": str(uuid.uuid4()).upper(),
                "material_id": effect_material_id,
                "target_timerange": {
                    "start": cursor_us,
                    "duration": effect_duration_us,
                },
            }
            final_effect_segs.append(new_effect_seg)

        cursor_us += final_video_duration_us
        video_cursor += 1

    for i in range(video_cursor, len(all_video_segments)):
        video_seg = deepcopy(all_video_segments[i])
        video_seg["target_timerange"]["start"] = cursor_us
        duration = int(video_seg.get("target_timerange", {}).get("duration", 0))
        cursor_us += duration
        final_video_segs.append(video_seg)

    new_tracks = [
        t for t in tracks if t.get("type") not in ["video", "audio", "text", "effect"]
    ]
    if final_video_segs:
        new_tracks.insert(
            0,
            {
                "type": "video",
                "segments": final_video_segs,
                "id": str(uuid.uuid4()).upper(),
                "attribute": 0,
                "flag": 0,
            },
        )
    if final_audio_segs:
        new_tracks.append(
            {
                "type": "audio",
                "segments": final_audio_segs,
                "id": str(uuid.uuid4()).upper(),
                "attribute": 0,
                "flag": 0,
            }
        )
    if final_text_segs:
        new_tracks.append(
            {
                "type": "text",
                "segments": final_text_segs,
                "id": str(uuid.uuid4()).upper(),
                "attribute": 0,
                "flag": 0,
            }
        )
    if final_effect_segs:
        new_tracks.append(
            {
                "type": "effect",
                "segments": final_effect_segs,
                "id": str(uuid.uuid4()).upper(),
                "attribute": 0,
                "flag": 0,
            }
        )

    json_data["tracks"] = new_tracks
    json_data["duration"] = max(int(json_data.get("duration", 0)), cursor_us)

    input_path = Path("draft_content.json")
    backup_path = Path("draft_content.json.bak")
    if input_path.exists():
        backup_path.write_text(input_path.read_text(encoding="utf-8"), encoding="utf-8")
        logging.info(f"\nƒê√£ t·∫°o backup: {backup_path}")

    with open(input_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=4)

    logging.info(f"‚úÖ X·ª≠ l√Ω th√†nh c√¥ng! ƒê√£ ƒë·ªìng b·ªô v√† t√°i x√¢y d·ª±ng timeline.")
    logging.info(
        "   (Ch·ªâ l√†m ch·∫≠m video khi audio d√†i h∆°n, gi·ªØ nguy√™n t·ªëc ƒë·ªô khi audio ng·∫Øn h∆°n)"
    )
    logging.info(
        "   üìù Text: Th·ªùi gian b·∫Øt ƒë·∫ßu = audio hi·ªán t·∫°i, th·ªùi gian k·∫øt th√∫c = audio ti·∫øp theo"
    )
    return True


def apply_style_only(json_file: str) -> bool:
    """
    CH·ª®C NƒÇNG M·ªöI: Ch·ªâ √°p d·ª•ng style cho T·∫§T C·∫¢ text m√† kh√¥ng thay ƒë·ªïi n·ªôi dung.
    C·∫¨P NH·∫¨T: √Åp d·ª•ng cho to√†n b·ªô text c·ªßa t·∫•t c·∫£ c√°c track text, kh√¥ng ch·ªâ ri√™ng vi-VN.
    """
    print(f"\n--- CH·ª®C NƒÇNG: CH·ªà √ÅP D·ª§NG STYLE ---")
    print(f"üìÅ ƒêang ƒë·ªçc file: {json_file}")
    print(f"üé® S·∫Ω √°p d·ª•ng style (font, size, m√†u s·∫Øc...) cho T·∫§T C·∫¢ text")
    print(f"üìù KH√îNG thay ƒë·ªïi n·ªôi dung text, ch·ªâ n√¢ng c·∫•p c·∫•u tr√∫c")

    # ƒê·ªçc file JSON
    json_data = load_json_file(json_file)
    if not json_data:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file '{json_file}'")
        return False

    # Ki·ªÉm tra c√≥ text n√†o kh√¥ng
    materials = json_data.get("materials", {})
    texts = materials.get("texts", [])

    if not texts:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y text n√†o trong d·ª± √°n.")
        return False

    print(f"üìä T√¨m th·∫•y {len(texts)} text ƒë·ªÉ √°p d·ª•ng style")

    # √Åp d·ª•ng style
    if apply_style_to_texts(json_data):
        # T·∫°o backup tr∆∞·ªõc khi l∆∞u
        backup_path = json_file + ".bak"
        try:
            if os.path.exists(json_file):
                if os.path.exists(backup_path):
                    os.remove(backup_path)
                os.rename(json_file, backup_path)
                print(f"üíæ ƒê√£ t·∫°o backup: {backup_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng th·ªÉ t·∫°o backup: {e}")

        # L∆∞u file v·ªõi style ƒë√£ √°p d·ª•ng
        try:
            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=4)
            print(f"‚úÖ ƒê√£ l∆∞u file v·ªõi style v√†o: {json_file}")
            return True
        except Exception as e:
            print(f"‚ùå L·ªói khi l∆∞u file {json_file}: {e}")
            return False
    else:
        print("‚ùå L·ªói trong qu√° tr√¨nh √°p d·ª•ng style.")
        return False


# ==============================================================================
# LOGIC FUNCTIONS FOR V7 METHODS
# ==============================================================================


def v7_export_captions_from_csv_logic(csv_file, json_file, output_dir):
    try:
        # Xu·∫•t caption vi-VN
        export_from_csv(csv_file, os.path.join(output_dir, "captions_vi.txt"))
        # Xu·∫•t caption ti·∫øng Trung v·ªõi gi·ªõi h·∫°n k√Ω t·ª±
        if json_file:
            results = get_translated_texts_with_timing(load_json_file(json_file))
        else:
            results = get_translated_texts_with_timing(
                load_json_file("draft_content.json")
            )
        export_chinese_with_char_count(
            results, os.path.join(output_dir, "captions_cn.txt")
        )
        return True
    except Exception as e:
        print(f"L·ªói: {e}")
        return False


def v7_replace_text_from_xlsx_logic(json_file, xlsx_file):
    return replace_vi_texts_in_draft_from_xlsx(json_file, xlsx_file)


def v7_apply_style_logic(json_file):
    return apply_style_only(json_file)


def v7_split_video_by_srt_logic(json_file, srt_file):
    json_data = load_json_file(json_file)
    if not json_data:
        return False
    return split_video_by_srt_timing(json_data, srt_file)


def v7_sync_video_audio_logic(json_file, video_start_index):
    json_data = load_json_file(json_file)
    if not json_data:
        return False
    return split_video_and_slow_down_for_audio(json_data, video_start_index)


def v7_split_by_character_logic(json_file, xlsx_file):
    json_data = load_json_file(json_file)
    if not json_data:
        return False
    return split_texts_into_multiple_tracks_by_character_index(json_data, xlsx_file)


def v7_export_cn_with_limit_logic(json_file, output_dir):
    try:
        results = get_translated_texts_with_timing(load_json_file(json_file))
        export_chinese_with_char_count(
            results, os.path.join(output_dir, "captions_cn_limit.txt")
        )
        return True
    except Exception as e:
        print(f"L·ªói: {e}")
        return False


def v7_export_to_srt(json_file: str, output_path: str) -> bool:
    """
    Xu·∫•t subtitle t·ª´ draft_content.json ra file SRT.
    L·∫•y text v√† timing t·ª´ extra_info > subtitle_fragment_info_list > sentence_list
    (ƒê√¢y l√† ngu·ªìn d·ªØ li·ªáu ch√≠nh x√°c m√† CapCut s·ª≠ d·ª•ng ƒë·ªÉ xu·∫•t SRT)
    """
    try:
        # ƒê·ªçc file JSON
        json_data = load_json_file(json_file)
        if not json_data:
            print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file '{json_file}'")
            return False
        
        # L·∫•y subtitle t·ª´ extra_info > subtitle_fragment_info_list
        srt_entries = []
        
        if 'extra_info' in json_data and json_data['extra_info'] is not None and isinstance(json_data['extra_info'], dict) and 'subtitle_fragment_info_list' in json_data['extra_info']:
            subtitle_fragments = json_data['extra_info']['subtitle_fragment_info_list']
            
            for fragment in subtitle_fragments:
                subtitle_cache_info = fragment.get('subtitle_cache_info', '')
                if not subtitle_cache_info:
                    continue
                
                try:
                    cache_info = json.loads(subtitle_cache_info)
                    if 'sentence_list' in cache_info and cache_info['sentence_list']:
                        for sentence in cache_info['sentence_list']:
                            # L·∫•y text t·ª´ sentence (text g·ªëc, kh√¥ng ph·∫£i translation)
                            text = sentence.get('text', '').strip()
                            if not text:
                                continue
                            
                            # L·∫•y timing t·ª´ sentence (ƒë√£ l√† milliseconds)
                            start_time_ms = sentence.get('start_time', 0)
                            end_time_ms = sentence.get('end_time', 0)
                            
                            # ƒê·∫£m b·∫£o timing h·ª£p l·ªá
                            if start_time_ms >= 0 and end_time_ms > start_time_ms:
                                # Lo·∫°i b·ªè HTML tags n·∫øu c√≥
                                clean_text = clean_text_from_html(text)
                                if clean_text:
                                    srt_entries.append({
                                        'start_time': int(start_time_ms),
                                        'end_time': int(end_time_ms),
                                        'text': clean_text
                                    })
                except Exception as e:
                    # B·ªè qua fragment l·ªói, ti·∫øp t·ª•c v·ªõi fragment ti·∫øp theo
                    continue
        
        if not srt_entries:
            print("‚ùå Kh√¥ng t√¨m th·∫•y subtitle n√†o t·ª´ extra_info > subtitle_fragment_info_list")
            # Th·ª≠ fallback: l·∫•y t·ª´ text tracks n·∫øu kh√¥ng c√≥ subtitle fragments
            print("   ƒêang th·ª≠ l·∫•y t·ª´ text tracks...")
            
            # L·∫•y text t·ª´ materials > texts
            materials = json_data.get('materials', {})
            texts_map = {}
            
            if materials and isinstance(materials, dict) and 'texts' in materials:
                for text_item in materials['texts']:
                    text_id = text_item.get('id', '')
                    if not text_id:
                        continue
                    
                    content = text_item.get('content', '')
                    text_content = extract_text_from_content(content)
                    
                    if not text_content:
                        recognize_text = text_item.get('recognize_text', '')
                        base_content = text_item.get('base_content', '')
                        text_content = clean_text_from_html(recognize_text) or clean_text_from_html(base_content)
                    
                    if text_content:
                        texts_map[text_id] = text_content.strip()
            
            # L·∫•y t·ª´ text tracks
            text_segments = []
            tracks = json_data.get('tracks', [])
            for track in tracks:
                if track.get('type') == 'text' and 'segments' in track:
                    text_segments.extend(track['segments'])
            
            text_segments.sort(key=lambda s: s.get('target_timerange', {}).get('start', 0))
            
            for segment in text_segments:
                material_id = segment.get('material_id', '')
                target_timerange = segment.get('target_timerange', {})
                start_us = target_timerange.get('start', 0)
                duration_us = target_timerange.get('duration', 0)
                end_us = start_us + duration_us
                
                text_content = texts_map.get(material_id, '')
                if not text_content:
                    segment_content = segment.get('content', '') or segment.get('text', '')
                    if segment_content:
                        text_content = extract_text_from_content(str(segment_content))
                
                if text_content:
                    start_ms = start_us // 1000
                    end_ms = end_us // 1000
                    if start_ms >= 0 and end_ms > start_ms:
                        srt_entries.append({
                            'start_time': start_ms,
                            'end_time': end_ms,
                            'text': text_content
                        })
        
        if not srt_entries:
            print("‚ùå Kh√¥ng t√¨m th·∫•y subtitle n√†o ƒë·ªÉ xu·∫•t")
            return False
        
        # S·∫Øp x·∫øp theo th·ªùi gian b·∫Øt ƒë·∫ßu
        srt_entries.sort(key=lambda x: x['start_time'])
        
        # Ghi ra file SRT
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                for idx, entry in enumerate(srt_entries, 1):
                    # S·ªë th·ª© t·ª±
                    f.write(f"{idx}\n")
                    
                    # Th·ªùi gian: HH:MM:SS,mmm --> HH:MM:SS,mmm
                    start_time_str = milliseconds_to_srt_time(entry['start_time'])
                    end_time_str = milliseconds_to_srt_time(entry['end_time'])
                    f.write(f"{start_time_str} --> {end_time_str}\n")
                    
                    # N·ªôi dung subtitle
                    f.write(f"{entry['text']}\n")
                    
                    # D√≤ng tr·ªëng gi·ªØa c√°c entry
                    f.write("\n")
            
            print(f"‚úÖ ƒê√£ xu·∫•t {len(srt_entries)} subtitle v√†o file: {output_path}")
            return True
        except Exception as e:
            print(f"‚ùå L·ªói khi ghi file SRT: {e}")
            return False
            
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω: {e}")
        import traceback
        traceback.print_exc()
        return False


def v7_export_csv_from_draft_logic(json_file, output_dir):
    try:
        json_data = load_json_file(json_file)
        if not json_data:
            return False
        # L·∫•y th√¥ng tin text ƒë√£ ƒë∆∞·ª£c translate
        results = get_translated_texts_with_timing(json_data)

        if not results:
            return False

        # L∆∞u k·∫øt qu·∫£ ra file CSV
        csv_file = os.path.join(output_dir, "translated_texts.csv")
        save_to_csv(results, csv_file)

        # Ki·ªÉm tra v√† t·∫°o file captions.xlsx n·∫øu ch∆∞a c√≥
        xlsx_file = os.path.join(output_dir, "captions.xlsx")
        create_captions_xlsx_if_not_exists(results, xlsx_file)

        return True
    except Exception as e:
        print(f"L·ªói: {e}")
        return False


def v7_find_idSubtile_and_nameAudio_sort(json_file, output_dir):
    """
    L·∫•y danh s√°ch t√™n audio (l√† c√°c text c√≥ audio ƒë√≠nh k√®m) t·ª´ draft_content.json.
    S·∫Øp x·∫øp theo th·ª© t·ª± subtitle t·ª´ extra_info.
    """
    try:
        # ƒê·ªçc file JSON
        json_data = load_json_file(json_file)
        if not json_data:
            print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file '{json_file}'")
            return False
        
        # L·∫•y danh s√°ch audio materials tr∆∞·ªõc
        materials = json_data.get('materials', {})
        audios = materials.get('audios', [])
        print(f"Debug: Found {len(audios)} audio materials")
        
        # T·∫°o mapping material_id -> text_id t·ª´ audios
        material_to_text_id = {}
        for audio in audios:
            if isinstance(audio, dict):
                material_id = audio.get('id', '')
                text_id = audio.get('text_id', '')
                if material_id and text_id:
                    material_to_text_id[material_id] = text_id
        
        # L·∫•y th·ª© t·ª± subtitle t·ª´ extra_info
        subtitle_order = []
        if (
            "extra_info" in json_data
            and json_data["extra_info"]
            and isinstance(json_data["extra_info"], dict)
        ):
            if "subtitle_fragment_info_list" in json_data["extra_info"]:
                fragments = json_data["extra_info"]["subtitle_fragment_info_list"]
                print(f"Debug: Found {len(fragments)} subtitle fragments")
                for fragment in fragments:
                    if "subtitle_cache_info" in fragment and fragment["subtitle_cache_info"]:
                        try:
                            cache_info = json.loads(fragment["subtitle_cache_info"])
                            if "sentence_list" in cache_info:
                                for sentence in cache_info["sentence_list"]:
                                    text_id = sentence.get("text_id", "")
                                    if text_id:
                                        subtitle_order.append(text_id)
                        except:
                            continue
        
        print(f"Debug: Found {len(subtitle_order)} subtitle text_ids")
        
        # N·∫øu kh√¥ng c√≥ subtitle_order, fallback: l·∫•y theo th·ª© t·ª± segments trong audio tracks
        if not subtitle_order:
            print("Debug: No subtitle order found, using audio track segments order as fallback")
            tracks = json_data.get('tracks', [])
            audio_segments = []
            for track in tracks:
                if track.get('type') == 'audio':
                    segments = track.get('segments', [])
                    for seg in segments:
                        material_id = seg.get('material_id', '')
                        start_time = seg.get('target_timerange', {}).get('start', 0)
                        if material_id in material_to_text_id:
                            audio_segments.append((start_time, material_to_text_id[material_id]))
            
            # S·∫Øp x·∫øp theo start_time
            audio_segments.sort(key=lambda x: x[0])
            subtitle_order = [text_id for _, text_id in audio_segments]
            print(f"Debug: Using {len(subtitle_order)} audio text_ids from track segments as order")
        
        # T·∫°o mapping text_id -> audio name
        audio_mapping = {}
        for audio in audios:
            if isinstance(audio, dict):
                path = audio.get('path', '')
                text_id = audio.get('text_id', '')
                if '/textReading/' in path and '.wav' in path and text_id:
                    # Tr√≠ch xu·∫•t t√™n ƒë·∫ßy ƒë·ªß t·ª´ path
                    start = path.find('/textReading/') + len('/textReading/')
                    end = path.find('.wav')
                    if start != -1 and end != -1:
                        full_name = path[start:end]
                        audio_mapping[text_id] = full_name
        
        logging.info(f"Debug: Found {len(audio_mapping)} audio mappings")
        
        # S·∫Øp x·∫øp theo th·ª© t·ª± subtitle
        audio_names = []
        for text_id in subtitle_order:
            if text_id in audio_mapping:
                audio_names.append(audio_mapping[text_id])
        
        logging.info(f"Debug: Matched {len(audio_names)} audio names from {len(subtitle_order)} subtitles")
        
        if not audio_names:
            logging.warning("‚ùå Kh√¥ng t√¨m th·∫•y audio n√†o kh·ªõp v·ªõi subtitles")
            return False
        
        # Xu·∫•t ra file
        output_file = os.path.join(output_dir, 'audio_names_sorted.txt')
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                for name in audio_names:
                    f.write(name + '\n')
            logging.info(f"‚úÖ ƒê√£ xu·∫•t {len(audio_names)} t√™n audio theo th·ª© t·ª± subtitle v√†o file: {output_file}")
            return output_file  # Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n file thay v√¨ True
        except Exception as e:
            logging.error(f"‚ùå L·ªói khi ghi file: {e}")
            return False
            
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi x·ª≠ l√Ω: {e}", exc_info=True)
        return False